"""
æ™ºèƒ½åŒ»ç”Ÿé—®è¯ŠAIç³»ç»Ÿ - Gradioå‰ç«¯
å…¼å®¹ Gradio 6.3.0
"""

import gradio as gr
import requests
import numpy as np
import uuid
import time
import io
from typing import List, Dict, Optional
from datetime import datetime
import soundfile as sf

# =====================================================
# é…ç½®å‚æ•°
# =====================================================

BACKEND_URL = "http://localhost:8002"
CHUNK_DURATION = 12  # æ¯12ç§’å‘é€ä¸€æ¬¡éŸ³é¢‘åˆ°åç«¯ï¼ˆæé«˜æœ‰æ•ˆè¯­éŸ³æ—¶é•¿ï¼Œé¿å…SDè¿‡çŸ­æŠ¥é”™ï¼‰
SAMPLE_RATE = 16000
MAX_BUFFER_DURATION = 30  # æœ€é•¿ç¼“å­˜æ—¶é•¿ï¼Œé¿å…æ— é™å¢é•¿

# =====================================================
# å…¨å±€çŠ¶æ€
# =====================================================

class SessionState:
    def __init__(self):
        self.session_id = None
        self.is_recording = False
        self.is_paused = False
        self.audio_buffer = []
        self.all_segments = []
        self.speaker_mapping = {}
        self.last_send_time = None
        self.chunk_counter = 0
        
    def start_new_session(self):
        self.session_id = f"session_{uuid.uuid4().hex[:8]}_{int(time.time())}"
        self.is_recording = True
        self.is_paused = False
        self.audio_buffer = []
        self.all_segments = []
        self.speaker_mapping = {}
        self.last_send_time = time.time()
        self.chunk_counter = 0
        
        try:
            requests.post(f"{BACKEND_URL}/reset_session", 
                         params={"session_id": self.session_id}, timeout=5)
        except:
            pass

state = SessionState()

# =====================================================
# å·¥å…·å‡½æ•°
# =====================================================

def numpy_to_wav_bytes(audio_data: np.ndarray, sample_rate: int = 16000) -> bytes:
    buffer = io.BytesIO()
    sf.write(buffer, audio_data, sample_rate, format='WAV', subtype='PCM_16')
    buffer.seek(0)
    return buffer.read()


def send_audio_to_backend(audio_data: np.ndarray, session_id: str) -> List[Dict]:
    try:
        wav_bytes = numpy_to_wav_bytes(audio_data, SAMPLE_RATE)
        files = {'file': ('audio.wav', wav_bytes, 'audio/wav')}
        params = {'session_id': session_id}
        
        print(f"Sending {len(audio_data)/SAMPLE_RATE:.1f}s audio to backend...")
        response = requests.post(f"{BACKEND_URL}/asr_sd", files=files, params=params, timeout=60)
        
        if response.status_code == 200:
            result = response.json()
            segments = result.get('segments', [])
            print(f"Received {len(segments)} segments")
            return segments
        else:
            print(f"Backend error: {response.status_code}")
            return []
    except Exception as e:
        print(f"Failed to send audio: {e}")
        return []


def merge_adjacent_segments(segments: List[Dict]) -> List[Dict]:
    if not segments:
        return []
    
    merged = []
    current = segments[0].copy()
    
    for seg in segments[1:]:
        if seg['speaker_id'] == current['speaker_id']:
            current['end'] = seg['end']
            current['text'] += " " + seg['text']
        else:
            merged.append(current)
            current = seg.copy()
    
    merged.append(current)
    return merged


def get_unique_speakers() -> List[str]:
    speakers = set()
    for seg in state.all_segments:
        speaker_id = seg.get('speaker_id')
        if speaker_id and speaker_id != 'unknown':
            speakers.add(speaker_id)
    return sorted(list(speakers))


def format_segment_text(seg: Dict, use_mapping: bool = False) -> str:
    """æ ¼å¼åŒ–å•ä¸ªç‰‡æ®µä¸ºæ–‡æœ¬"""
    speaker_id = seg.get('speaker_id', 'unknown')
    text = seg.get('text', '')
    start = seg.get('start', 0)
    end = seg.get('end', 0)
    
    if use_mapping and speaker_id in state.speaker_mapping:
        display_name = state.speaker_mapping[speaker_id]
    else:
        display_name = speaker_id
    
    return f"[{start:.1f}s-{end:.1f}s] {display_name}: {text}"


def build_conversation_text(use_mapping: bool = False) -> str:
    """æ„å»ºå¯¹è¯æ–‡æœ¬æ˜¾ç¤º"""
    if not state.all_segments:
        return "æš‚æ— å¯¹è¯è®°å½•"
    
    segments = state.all_segments
    if not state.is_recording:
        segments = merge_adjacent_segments(segments)
    
    lines = []
    for seg in segments:
        lines.append(format_segment_text(seg, use_mapping))
    
    return "\n\n".join(lines)


# =====================================================
# æŒ‰é’®äº‹ä»¶å¤„ç†
# =====================================================

def start_consultation():
    state.start_new_session()
    return (
        gr.update(interactive=False),  # start_btn
        gr.update(interactive=True),   # pause_btn
        gr.update(interactive=True),   # end_btn
        "",  # conversation_display
        gr.update(visible=False),  # speaker_settings
        gr.update(interactive=False),  # report_btn
        f"âœ… é—®è¯Šå·²å¼€å§‹ | ä¼šè¯ID: {state.session_id}"
    )


def pause_consultation():
    if state.is_paused:
        state.is_paused = False
        return gr.update(value="â¸ï¸ æš‚åœ"), "â–¶ï¸ é—®è¯Šå·²æ¢å¤"
    else:
        state.is_paused = True
        return gr.update(value="â–¶ï¸ ç»§ç»­"), "â¸ï¸ é—®è¯Šå·²æš‚åœ"


def end_consultation():
    state.is_recording = False
    state.is_paused = False
    
    conversation_text = build_conversation_text(use_mapping=False)
    speakers = get_unique_speakers()
    
    return (
        gr.update(interactive=True),   # start_btn
        gr.update(interactive=False),  # pause_btn
        gr.update(interactive=False),  # end_btn
        conversation_text,  # conversation_display
        gr.update(visible=True),  # speaker_settings
        gr.update(interactive=False),  # report_btn
        f"ğŸ é—®è¯Šå·²ç»“æŸ | æ£€æµ‹åˆ° {len(speakers)} ä½è¯´è¯äºº"
    )


def apply_speaker_mapping(speaker_inputs):
    """åº”ç”¨è¯´è¯äººèº«ä»½æ˜ å°„"""
    speakers = get_unique_speakers()
    
    # è§£æè¾“å…¥çš„æ˜ å°„
    state.speaker_mapping = {}
    for line in speaker_inputs.strip().split('\n'):
        if ':' in line:
            parts = line.split(':', 1)
            if len(parts) == 2:
                spk_id = parts[0].strip()
                spk_name = parts[1].strip()
                if spk_id in speakers and spk_name:
                    state.speaker_mapping[spk_id] = spk_name
    
    conversation_text = build_conversation_text(use_mapping=True)
    
    return (
        conversation_text,
        gr.update(interactive=True),
        f"âœ… å·²åº”ç”¨ {len(state.speaker_mapping)} ä½è¯´è¯äººçš„èº«ä»½æ˜ å°„"
    )


def reset_speaker_mapping():
    state.speaker_mapping = {}
    conversation_text = build_conversation_text(use_mapping=False)
    return (
        conversation_text,
        gr.update(interactive=False),
        "ğŸ”„ èº«ä»½æ˜ å°„å·²é‡ç½®"
    )


def generate_speaker_mapping_template():
    """ç”Ÿæˆè¯´è¯äººæ˜ å°„æ¨¡æ¿"""
    speakers = get_unique_speakers()
    if not speakers:
        return "æš‚æ— è¯´è¯äºº"
    
    template_lines = []
    for speaker in speakers:
        template_lines.append(f"{speaker}: ")
    
    return "\n".join(template_lines)


def generate_report():
    report = f"""# é—®è¯ŠæŠ¥å‘Š

**ä¼šè¯ID:** {state.session_id}
**é—®è¯Šæ—¶é—´:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
**è¯´è¯äººæ•°é‡:** {len(get_unique_speakers())}

## è¯´è¯äººèº«ä»½
"""
    if state.speaker_mapping:
        for k, v in state.speaker_mapping.items():
            report += f"- {k}: {v}\n"
    else:
        report += "æœªè®¾ç½®èº«ä»½æ˜ å°„\n"
    
    report += "\n## å¯¹è¯è®°å½•\n\n"
    
    segments = merge_adjacent_segments(state.all_segments)
    for seg in segments:
        speaker_id = seg['speaker_id']
        display_name = state.speaker_mapping.get(speaker_id, speaker_id)
        report += f"**{display_name}** [{seg['start']:.1f}s - {seg['end']:.1f}s]\n\n{seg['text']}\n\n"
    
    return report


# =====================================================
# éŸ³é¢‘æµå¤„ç†
# =====================================================

def process_audio_stream(audio):
    if not state.is_recording or state.is_paused:
        return build_conversation_text(use_mapping=False), "ç­‰å¾…å½•éŸ³..."
    
    if audio is None:
        return build_conversation_text(use_mapping=False), "æœªæ£€æµ‹åˆ°éŸ³é¢‘"
    
    sample_rate, audio_data = audio
    
    # è½¬å•å£°é“
    if len(audio_data.shape) > 1:
        audio_data = audio_data.mean(axis=1)
    
    # é‡é‡‡æ ·
    if sample_rate != SAMPLE_RATE:
        ratio = SAMPLE_RATE / sample_rate
        new_length = int(len(audio_data) * ratio)
        audio_data = np.interp(
            np.linspace(0, len(audio_data) - 1, new_length),
            np.arange(len(audio_data)),
            audio_data
        )
    
    # å½’ä¸€åŒ–
    if audio_data.dtype != np.float32:
        audio_data = audio_data.astype(np.float32) / 32768.0
    
    state.audio_buffer.append(audio_data)
    
    buffer_duration = sum(len(chunk) for chunk in state.audio_buffer) / SAMPLE_RATE
    status_msg = f"å½•éŸ³ä¸­... ç¼“å†²åŒº: {buffer_duration:.1f}s"
    
    if buffer_duration >= CHUNK_DURATION:
        full_audio = np.concatenate(state.audio_buffer)
        
        status_msg = f"æ­£åœ¨å‘é€éŸ³é¢‘å— #{state.chunk_counter + 1}..."
        segments = send_audio_to_backend(full_audio, state.session_id)
        
        if segments:
            state.all_segments.extend(segments)
            state.chunk_counter += 1
            status_msg = f"âœ… å·²æ¥æ”¶å— #{state.chunk_counter} | æ£€æµ‹åˆ° {len(segments)} ä¸ªç‰‡æ®µ"
            overlap_samples = int(0.5 * SAMPLE_RATE)
            if len(full_audio) > overlap_samples:
                state.audio_buffer = [full_audio[-overlap_samples:]]
            else:
                state.audio_buffer = []
        else:
            # æœªè¿”å›ç‰‡æ®µæ—¶ï¼Œä¿ç•™ç¼“å­˜ä»¥ç´¯ç§¯æ›´é•¿è¯­éŸ³ï¼ˆé¿å…ä¸¢éŸ³ï¼‰
            status_msg = "âš ï¸ è¯­éŸ³æœ‰æ•ˆæ—¶é•¿ä¸è¶³ï¼Œç»§ç»­ç´¯ç§¯ä¸­..."
            # é™åˆ¶æœ€å¤§ç¼“å­˜é•¿åº¦ï¼Œé˜²æ­¢å†…å­˜å¢é•¿
            max_samples = int(MAX_BUFFER_DURATION * SAMPLE_RATE)
            if len(full_audio) > max_samples:
                state.audio_buffer = [full_audio[-max_samples:]]
        
        state.last_send_time = time.time()
    
    return build_conversation_text(use_mapping=False), status_msg


# =====================================================
# Gradio ç•Œé¢
# =====================================================

with gr.Blocks(title="æ™ºèƒ½åŒ»ç”Ÿé—®è¯ŠAIç³»ç»Ÿ") as demo:
    gr.Markdown("# ğŸ¥ æ™ºèƒ½åŒ»ç”Ÿé—®è¯ŠAIç³»ç»Ÿ")
    gr.Markdown("åŸºäºè¯­éŸ³è¯†åˆ«å’Œè¯´è¯äººåˆ†ç¦»çš„å®æ—¶é—®è¯Šè®°å½•ç³»ç»Ÿ")
    
    gr.Markdown("""
    <div style="background: #fff3cd; padding: 10px; border-radius: 5px; margin-bottom: 15px;">
        <strong>âš ï¸ ä½¿ç”¨æç¤ºï¼š</strong>
        <ul style="margin: 5px 0;">
            <li>è¯·ä½¿ç”¨ <code>http://localhost:7860</code> æˆ– <code>http://127.0.0.1:7860</code> è®¿é—®ä»¥å¯ç”¨éº¦å…‹é£</li>
            <li>é¦–æ¬¡ä½¿ç”¨æ—¶æµè§ˆå™¨ä¼šè¯·æ±‚éº¦å…‹é£æƒé™ï¼Œè¯·ç‚¹å‡»"å…è®¸"</li>
            <li>ç¡®ä¿åç«¯æœåŠ¡å·²å¯åŠ¨ï¼ˆç«¯å£8002ï¼‰</li>
        </ul>
    </div>
    """)
    
    with gr.Row():
        # å·¦ä¾§
        with gr.Column(scale=2):
            status_display = gr.Textbox(
                label="ç³»ç»ŸçŠ¶æ€",
                value="å‡†å¤‡å°±ç»ªï¼Œç‚¹å‡»ã€Œå¼€å§‹é—®è¯Šã€å¼€å§‹å½•éŸ³",
                interactive=False
            )
            
            with gr.Row():
                start_btn = gr.Button("ğŸ™ï¸ å¼€å§‹é—®è¯Š", variant="primary")
                pause_btn = gr.Button("â¸ï¸ æš‚åœ", interactive=False)
                end_btn = gr.Button("ğŸ ç»“æŸé—®è¯Š", interactive=False)
            
            audio_input = gr.Audio(
                sources=["microphone"],
                streaming=True,
                label="å½•éŸ³è¾“å…¥"
            )
            
            gr.Markdown("### ğŸ’¬ å®æ—¶å¯¹è¯è½¬å½•")
            conversation_display = gr.Textbox(
                label="å¯¹è¯è®°å½•",
                lines=20,
                interactive=False,
                placeholder="å¯¹è¯å†…å®¹å°†åœ¨è¿™é‡Œæ˜¾ç¤º..."
            )
        
        # å³ä¾§
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ‘¥ è¯´è¯äººèº«ä»½è®¾ç½®")
            
            with gr.Column(visible=False) as speaker_settings:
                gr.Markdown("è¯·ä¸ºæ¯ä½è¯´è¯äººè®¾ç½®èº«ä»½ï¼ˆæ ¼å¼ï¼šspeaker_1: å¼ åŒ»ç”Ÿï¼‰")
                
                mapping_template_btn = gr.Button("ç”Ÿæˆæ¨¡æ¿", size="sm")
                
                speaker_mapping_input = gr.Textbox(
                    label="è¯´è¯äººèº«ä»½æ˜ å°„",
                    lines=8,
                    placeholder="speaker_1: å¼ åŒ»ç”Ÿ\nspeaker_2: æ‚£è€…ææŸ\nspeaker_3: å®¶å±",
                    interactive=True
                )
                
                with gr.Row():
                    apply_btn = gr.Button("âœ… åº”ç”¨è®¾ç½®", variant="primary")
                    reset_btn = gr.Button("ğŸ”„ é‡ç½®")
            
            gr.Markdown("### ğŸ“‹ ç»“æ„åŒ–æŠ¥å‘Š")
            report_btn = gr.Button("ç”ŸæˆæŠ¥å‘Š", interactive=False)
            report_output = gr.Markdown(value="")
    
    # äº‹ä»¶ç»‘å®š
    start_btn.click(
        fn=start_consultation,
        outputs=[start_btn, pause_btn, end_btn, conversation_display, 
                speaker_settings, report_btn, status_display]
    )
    
    pause_btn.click(
        fn=pause_consultation,
        outputs=[pause_btn, status_display]
    )
    
    end_btn.click(
        fn=end_consultation,
        outputs=[start_btn, pause_btn, end_btn, conversation_display,
                speaker_settings, report_btn, status_display]
    )
    
    audio_input.stream(
        fn=process_audio_stream,
        inputs=[audio_input],
        outputs=[conversation_display, status_display],
        stream_every=1.0
    )
    
    mapping_template_btn.click(
        fn=generate_speaker_mapping_template,
        outputs=[speaker_mapping_input]
    )
    
    apply_btn.click(
        fn=apply_speaker_mapping,
        inputs=[speaker_mapping_input],
        outputs=[conversation_display, report_btn, status_display]
    )
    
    reset_btn.click(
        fn=reset_speaker_mapping,
        outputs=[conversation_display, report_btn, status_display]
    )
    
    report_btn.click(
        fn=generate_report,
        outputs=[report_output]
    )


if __name__ == "__main__":
    print("=" * 60)
    print("æ™ºèƒ½åŒ»ç”Ÿé—®è¯ŠAIç³»ç»Ÿ - Gradio 6.3.0")
    print("=" * 60)
    print("ğŸ“ æœ¬åœ°è®¿é—®: http://localhost:7860")
    print("âš ï¸  éº¦å…‹é£éœ€è¦HTTPSæˆ–localhostè®¿é—®")
    print("=" * 60)
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False
    )