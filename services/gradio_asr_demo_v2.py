import gradio as gr
import json
import time
import uuid
import requests
import threading
from datetime import datetime
from typing import Dict, List, Tuple
import numpy as np
import io
import wave

# ==================== é…ç½® ====================
BACKEND_API_URL = "http://localhost:8002/asr_sd"
CHUNK_DURATION = 30  # æ¯æ¬¡å½•éŸ³åˆ†æ®µæ—¶é•¿(ç§’) â€” æ‹‰é•¿ä»¥ä¿æŒè¯´è¯äººè¿ç»­æ€§
SAMPLE_RATE = 16000  # é‡‡æ ·ç‡
MIN_AUDIO_LENGTH = SAMPLE_RATE * CHUNK_DURATION  # æœ€å°éŸ³é¢‘é•¿åº¦(é‡‡æ ·ç‚¹æ•°)
ROLE_OPTIONS = ["æ‚£è€…", "å®¶å±/é™ªè¯Š", "åŒ»ç”Ÿ", "æŠ¤å£«", "å…¶ä»–"]
MAX_SPEAKERS = 4  # é¢„ç•™æœ€å¤š4ä¸ªè¯´è¯äººä¸‹æ‹‰è¡Œ

# ==================== å…¨å±€çŠ¶æ€ç®¡ç† ====================
class ConsultationState:
    def __init__(self):
        self.is_recording = False
        self.is_paused = False
        self.transcripts = []  # å­˜å‚¨æ‰€æœ‰è½¬å½•å†…å®¹
        self.speaker_mapping = {}  # è¯´è¯äººIDåˆ°èº«ä»½çš„æ˜ å°„
        self.unique_speakers = set()  # æ£€æµ‹åˆ°çš„è¯´è¯äººé›†åˆ
        self.mapping_done = False  # æ˜¯å¦å®Œæˆèº«ä»½æ˜ å°„
        self.start_time = None
        self.session_id = None  # åç«¯ä¼šè¯ID
        self.speaker_label_map = {}  # backend speaker_id -> ç”¨æˆ·X
        self.audio_buffer = []  # ç´¯ç§¯çš„éŸ³é¢‘æ•°æ®(numpy array)
        self.recording_thread = None
        self.processed_chunks = 0  # å·²å¤„ç†çš„éŸ³é¢‘å—æ•°é‡
        self.total_audio_samples = 0  # ç´¯ç§¯çš„éŸ³é¢‘é‡‡æ ·ç‚¹æ€»æ•°
        self.transcript_version = 0  # ç”¨äºå‡å°‘æ— æ„ä¹‰UIåˆ·æ–°
        self.last_rendered_version = -1
        self.last_ui_render_time = 0.0
        self.cached_transcript_html = ""
        self.buffer_lock = threading.Lock()  # ä¿æŠ¤éŸ³é¢‘ç¼“å†²åŒºçš„é”
        self.is_processing = False  # æ ‡è®°æ˜¯å¦æ­£åœ¨å¤„ç†éŸ³é¢‘å—
        
    def reset(self):
        self.__init__()

state = ConsultationState()

# ==================== åç«¯APIè°ƒç”¨ ====================
def call_backend_api(audio_data: bytes) -> List[Dict]:
    """
    è°ƒç”¨åç«¯ASR+SD API
    audio_data: WAVæ ¼å¼çš„éŸ³é¢‘å­—èŠ‚æµ
    è¿”å›: [{"start": float, "end": float, "speaker": str, "text": str}, ...]
    """
    try:
        files = {"file": ("chunk.wav", audio_data, "audio/wav")}
        # åç«¯v5è¦æ±‚session_id,ç”¨UUIDä¿æŒåŒä¸€é—®è¯Šä¼šè¯
        if not state.session_id:
            state.session_id = uuid.uuid4().hex

        response = requests.post(
            BACKEND_API_URL,
            params={"session_id": state.session_id},
            files=files,
            timeout=30
        )

        if response.status_code != 200:
            print(f"API Error: {response.status_code} - {response.text}")
            return []

        data = response.json()
        segments = data.get("segments", []) if isinstance(data, dict) else data

        normalized = []
        for seg in segments:
            speaker_id = seg.get("speaker_id") or seg.get("speaker") or "unknown"
            display = state.speaker_label_map.setdefault(
                speaker_id,
                f"ç”¨æˆ·{len(state.speaker_label_map) + 1}"
            )

            normalized.append({
                "start": float(seg.get("start", 0.0)),
                "end": float(seg.get("end", 0.0)),
                "speaker": display,
                "text": seg.get("text", "").strip()
            })

        return normalized
    except Exception as e:
        print(f"Backend API call failed: {str(e)}")
        return []

def convert_audio_to_wav(audio_array, sample_rate=16000):
    """
    å°†éŸ³é¢‘æ•°ç»„è½¬æ¢ä¸ºWAVæ ¼å¼çš„å­—èŠ‚æµ
    """
    buffer = io.BytesIO()
    
    # ç¡®ä¿éŸ³é¢‘æ•°æ®æ˜¯int16æ ¼å¼
    if audio_array.dtype != np.int16:
        audio_array = (audio_array * 32767).astype(np.int16)
    
    with wave.open(buffer, 'wb') as wav_file:
        wav_file.setnchannels(1)  # å•å£°é“
        wav_file.setsampwidth(2)  # 16bit
        wav_file.setframerate(sample_rate)
        wav_file.writeframes(audio_array.tobytes())
    
    buffer.seek(0)
    return buffer.read()


def has_enough_voice(audio_array: np.ndarray, sample_rate: int, min_voice_seconds: float = 3.0, energy_threshold: float = 0.01) -> Tuple[bool, float]:
    """ç®€å•èƒ½é‡æ£€æµ‹: æœ‰æ•ˆè¯­éŸ³æ—¶é•¿ä¸è¶³æ—¶è·³è¿‡è°ƒç”¨åç«¯,é¿å…æ— æ•ˆè¯·æ±‚"""
    if audio_array.size == 0:
        return False, 0.0

    audio = audio_array.astype(np.float32)
    # å¦‚æœæ˜¯int16,ç¼©æ”¾åˆ°[-1,1]
    if audio.max(initial=0) > 1.5:
        audio = audio / 32768.0

    frame = max(int(0.02 * sample_rate), 1)  # 20mså¸§
    if len(audio) < frame:
        return False, 0.0

    # æ»‘åŠ¨å‡æ–¹æ ¹èƒ½é‡
    window = np.ones(frame) / frame
    rms = np.sqrt(np.convolve(audio ** 2, window, mode="valid"))
    voiced = rms > energy_threshold
    voiced_duration = voiced.sum() * (frame / sample_rate)

    return voiced_duration >= min_voice_seconds, float(voiced_duration)

# ==================== æ ¸å¿ƒåŠŸèƒ½å‡½æ•° ====================

def format_time(seconds: float) -> str:
    """æ ¼å¼åŒ–æ—¶é—´ä¸º MM:SS"""
    minutes = int(seconds // 60)
    secs = int(seconds % 60)
    return f"{minutes:02d}:{secs:02d}"

def format_transcript_html(transcripts: List[Dict], mapping_done: bool, speaker_mapping: Dict) -> str:
    """æ ¼å¼åŒ–å¯¹è¯è½¬å½•ä¸ºHTML"""
    if not transcripts:
        return '<div style="color: #999; text-align: center; padding: 20px;">æš‚æ— å¯¹è¯å†…å®¹</div>'
    
    html = '<div style="display: flex; flex-direction: column; gap: 15px; max-height: 500px; overflow-y: auto; padding: 10px;">'
    
    for item in transcripts:
        speaker_label = item['speaker']  # "ç”¨æˆ·1", "ç”¨æˆ·2" ç­‰
        text = item['text']
        time_range = f"{format_time(item['start'])}-{format_time(item['end'])}"
        
        # ç¡®å®šè¯´è¯äººæ˜¾ç¤ºåç§°
        if mapping_done and speaker_label in speaker_mapping:
            speaker_name = speaker_mapping[speaker_label]['name']
            role = speaker_mapping[speaker_label]['role']
            is_hospital = role in ['doctor', 'nurse']
        else:
            speaker_name = speaker_label
            is_hospital = False
        
        # ç¡®å®šæ¶ˆæ¯ä½ç½®å’Œæ ·å¼
        if mapping_done:
            if is_hospital:
                # åŒ»é™¢æ–¹ - å³ä¾§,è“è‰²
                align = "flex-end"
                bg_color = "#e3f2fd"
                name_color = "#1e90ff"
                border_radius = "12px 12px 4px 12px"
            else:
                # æ‚£è€…æ–¹ - å·¦ä¾§,ç»¿è‰²
                align = "flex-start"
                bg_color = "#e8f5e9"
                name_color = "#4caf50"
                border_radius = "12px 12px 12px 4px"
        else:
            # æœªæ˜ å°„ - å·¦ä¾§,ç°è‰²
            align = "flex-start"
            bg_color = "#f0f0f0"
            name_color = "#666"
            border_radius = "12px 12px 12px 4px"
        
        html += f'''
        <div style="display: flex; justify-content: {align};">
            <div style="
                max-width: 80%;
                padding: 12px 16px;
                background-color: {bg_color};
                border-radius: {border_radius};
                box-shadow: 0 2px 4px rgba(0,0,0,0.1);
            ">
                <div style="font-size: 12px; font-weight: 600; color: {name_color}; margin-bottom: 5px;">
                    {speaker_name}
                </div>
                <div style="font-size: 14px; line-height: 1.6; color: #333;">
                    {text}
                </div>
                <div style="font-size: 11px; color: #999; text-align: right; margin-top: 5px;">
                    {time_range}
                </div>
            </div>
        </div>
        '''
    
    html += '</div>'
    return html

def merge_consecutive_speakers(transcripts: List[Dict]) -> List[Dict]:
    """åˆå¹¶ç›¸é‚»åŒä¸€è¯´è¯äººçš„å†…å®¹"""
    if not transcripts:
        return []
    
    merged = []
    current = transcripts[0].copy()
    
    for i in range(1, len(transcripts)):
        if transcripts[i]['speaker'] == current['speaker']:
            # åˆå¹¶æ–‡æœ¬å’Œæ—¶é—´
            current['text'] += ' ' + transcripts[i]['text']
            current['end'] = transcripts[i]['end']
        else:
            merged.append(current)
            current = transcripts[i].copy()
    
    merged.append(current)
    return merged

def create_speaker_mapping_ui(speaker_labels: List[str]) -> List[List]:
    """åˆ›å»ºè¯´è¯äººèº«ä»½æ˜ å°„UIçš„æ•°æ®"""
    if not speaker_labels:
        return []
    
    rows = []
    for idx, speaker_label in enumerate(sorted(speaker_labels)):
        # é»˜è®¤çŒœæµ‹:ç”¨æˆ·1å¯èƒ½æ˜¯æ‚£è€…,ç”¨æˆ·2å¯èƒ½æ˜¯åŒ»ç”Ÿ
        if speaker_label == "ç”¨æˆ·1":
            default_role = "æ‚£è€…"
            default_name = "æ‚£è€…1"
        elif speaker_label == "ç”¨æˆ·2":
            default_role = "åŒ»ç”Ÿ"
            default_name = "åŒ»ç”Ÿ"
        else:
            default_role = "å…¶ä»–"
            default_name = speaker_label
        
        rows.append([speaker_label, default_role, default_name])
    
    return rows


def build_mapping_updates(mapping_data: List[List]) -> Tuple:
    """å°†æ˜ å°„æ•°æ®è¡Œè½¬æ¢ä¸ºæ§ä»¶update; è¾“å‡ºé¡ºåº: å…¨éƒ¨label, å…¨éƒ¨role, å…¨éƒ¨name"""
    if not mapping_data:
        mapping_data = []

    labels = ["" for _ in range(MAX_SPEAKERS)]
    roles = ["æ‚£è€…" for _ in range(MAX_SPEAKERS)]
    names = ["" for _ in range(MAX_SPEAKERS)]

    for idx, row in enumerate(mapping_data[:MAX_SPEAKERS]):
        if len(row) >= 1:
            labels[idx] = row[0]
        if len(row) >= 2 and row[1] in ROLE_OPTIONS:
            roles[idx] = row[1]
        if len(row) >= 3:
            names[idx] = row[2]

    label_updates = []
    role_updates = []
    name_updates = []
    for i in range(MAX_SPEAKERS):
        visible = bool(labels[i])
        label_updates.append(gr.update(value=labels[i], visible=visible))
        role_updates.append(gr.update(value=roles[i], choices=ROLE_OPTIONS, visible=visible))
        name_updates.append(gr.update(value=names[i], visible=visible))
    return tuple(label_updates + role_updates + name_updates)


def build_empty_mapping_updates() -> Tuple:
    label_updates = []
    role_updates = []
    name_updates = []
    for _ in range(MAX_SPEAKERS):
        label_updates.append(gr.update(value="", visible=False))
        role_updates.append(gr.update(value="æ‚£è€…", choices=ROLE_OPTIONS, visible=False))
        name_updates.append(gr.update(value="", visible=False))
    return tuple(label_updates + role_updates + name_updates)

# ==================== éŸ³é¢‘å¤„ç†å’Œå®æ—¶è½¬å½• ====================

def process_audio_chunk(audio_chunk, sample_rate):
    """
    å¤„ç†å•ä¸ªéŸ³é¢‘å—:
    1. è½¬æ¢ä¸ºWAVæ ¼å¼
    2. è°ƒç”¨åç«¯API
    3. æ›´æ–°è½¬å½•ç»“æœ
    """
    try:
        # è½¬æ¢éŸ³é¢‘æ ¼å¼
        wav_data = convert_audio_to_wav(audio_chunk, sample_rate)
        
        # è°ƒç”¨åç«¯API
        results = call_backend_api(wav_data)
        
        if results:
            # è®¡ç®—æ—¶é—´åç§»(åŸºäºå·²å¤„ç†çš„éŸ³é¢‘å—)
            time_offset = state.processed_chunks * CHUNK_DURATION
            
            # è°ƒæ•´æ—¶é—´æˆ³å¹¶æ·»åŠ åˆ°è½¬å½•åˆ—è¡¨
            for item in results:
                adjusted_item = {
                    'speaker': item['speaker'],
                    'text': item['text'],
                    'start': item['start'] + time_offset,
                    'end': item['end'] + time_offset
                }
                state.transcripts.append(adjusted_item)
                state.unique_speakers.add(item['speaker'])
            
            state.processed_chunks += 1
            state.transcript_version += 1  # æ ‡è®°æœ‰æ–°å†…å®¹,è§¦å‘UIåˆ·æ–°
            return True
        
        return False
        
    except Exception as e:
        print(f"Error processing audio chunk: {str(e)}")
        return False

# ==================== äº‹ä»¶å¤„ç†å‡½æ•° ====================

def start_consultation():
    """å¼€å§‹é—®è¯Š"""
    state.reset()
    state.session_id = uuid.uuid4().hex  # ä¸ºæœ¬æ¬¡é—®è¯Šç”Ÿæˆsession_id
    state.is_recording = True
    state.start_time = datetime.now()
    state.cached_transcript_html = format_transcript_html([], False, {})
    state.last_rendered_version = state.transcript_version
    state.last_ui_render_time = time.time()
    
    return (
        gr.update(interactive=False),  # å¼€å§‹æŒ‰é’®
        gr.update(interactive=True),   # æš‚åœæŒ‰é’®
        gr.update(interactive=True),   # ç»“æŸæŒ‰é’®
        gr.update(value="<div style='color: #4cd964;'>â— é—®è¯Šä¸­...</div>"),  # çŠ¶æ€æŒ‡ç¤º
        format_transcript_html([], False, {}),  # æ¸…ç©ºå¯¹è¯
        gr.update(value="æç¤º:é—®è¯Šç»“æŸå,è¯·ä¸ºæ£€æµ‹åˆ°çš„è¯´è¯äººåˆ†é…èº«ä»½ã€‚è®¾ç½®ä¸º\"åŒ»ç”Ÿ\"æˆ–\"æŠ¤å£«\"èº«ä»½çš„æ¶ˆæ¯å°†æ˜¾ç¤ºåœ¨å³ä¾§,å…¶ä»–èº«ä»½æ¶ˆæ¯æ˜¾ç¤ºåœ¨å·¦ä¾§ã€‚"),
        gr.update(interactive=False),  # åº”ç”¨è®¾ç½®æŒ‰é’®
        gr.update(interactive=False),  # é‡ç½®è®¾ç½®æŒ‰é’®
        gr.update(interactive=False),  # ç”ŸæˆæŠ¥å‘ŠæŒ‰é’®
        gr.update(value=""),  # æ¸…ç©ºæŠ¥å‘Š
        f"0 æ¡å¯¹è¯",  # å¯¹è¯è®¡æ•°
        "ç­‰å¾…å½•éŸ³...",  # éŸ³é¢‘çŠ¶æ€
        gr.update(visible=False),  # éŸ³é¢‘ç»„ä»¶å ä½
        None  # å ä½: æ˜ å°„æ•°æ®
    )

def pause_consultation():
    """æš‚åœ/ç»§ç»­é—®è¯Š"""
    state.is_paused = not state.is_paused
    
    if state.is_paused:
        status_text = "<div style='color: #ff9500;'>â¸ å·²æš‚åœ</div>"
        pause_btn_text = "â–¶ï¸ ç»§ç»­"
    else:
        status_text = "<div style='color: #4cd964;'>â— é—®è¯Šä¸­...</div>"
        pause_btn_text = "â¸ æš‚åœ"
    
    return gr.update(value=status_text), gr.update(value=pause_btn_text)

def stop_consultation():
    """ç»“æŸé—®è¯Š"""
    state.is_recording = False
    
    # ç­‰å¾…å½“å‰å¤„ç†å®Œæˆ
    while state.is_processing:
        time.sleep(0.1)
    
    # ğŸ”’ å¤„ç†ç¼“å†²åŒºä¸­çš„å‰©ä½™éŸ³é¢‘ï¼ˆåŠ é”ä¿æŠ¤ï¼‰
    with state.buffer_lock:
        if state.audio_buffer and state.total_audio_samples > 0:
            combined_audio = np.concatenate(state.audio_buffer)
            state.audio_buffer = []
            state.total_audio_samples = 0
        else:
            combined_audio = None
    
    if combined_audio is not None and len(combined_audio) > SAMPLE_RATE:  # è‡³å°‘1ç§’
        voice_ok, voiced_secs = has_enough_voice(combined_audio, SAMPLE_RATE)
        if voice_ok:
            process_audio_chunk(combined_audio, SAMPLE_RATE)
        else:
            print(f"Skip final chunk: voiced {voiced_secs:.2f}s < min")
    
    # ç­‰å¾…å½•éŸ³çº¿ç¨‹ç»“æŸ
    if state.recording_thread and state.recording_thread.is_alive():
        state.recording_thread.join(timeout=2)
    
    # åˆå¹¶ç›¸é‚»åŒä¸€è¯´è¯äººçš„å¯¹è¯
    state.transcripts = merge_consecutive_speakers(state.transcripts)
    
    # ç»Ÿè®¡è¯´è¯äºº
    state.unique_speakers = set(t['speaker'] for t in state.transcripts)
    
    # åˆ›å»ºæ˜ å°„è¡¨æ ¼æ•°æ®
    mapping_data = create_speaker_mapping_ui(list(state.unique_speakers))
    
    speaker_count = len(state.unique_speakers)
    
    return (
        gr.update(interactive=True),   # å¼€å§‹æŒ‰é’®
        gr.update(interactive=False, value="â¸ æš‚åœ"),  # æš‚åœæŒ‰é’®
        gr.update(interactive=False),  # ç»“æŸæŒ‰é’®
        gr.update(value="<div style='color: #666;'>âœ“ é—®è¯Šå·²ç»“æŸ</div>"),  # çŠ¶æ€
        format_transcript_html(state.transcripts, False, {}),  # åˆ·æ–°å¯¹è¯æ˜¾ç¤º
        mapping_data,
        gr.update(value=f"é—®è¯Šç»“æŸ,å…±æ£€æµ‹åˆ° {speaker_count} ä¸ªè¯´è¯äººã€‚è¯·è®¾ç½®è¯´è¯äººèº«ä»½åç‚¹å‡»\"åº”ç”¨è®¾ç½®\"ã€‚"),
        gr.update(interactive=True),   # å¯ç”¨åº”ç”¨è®¾ç½®
        gr.update(interactive=True),   # å¯ç”¨é‡ç½®è®¾ç½®
        gr.update(interactive=False),  # ç”ŸæˆæŠ¥å‘Šä»ç¦ç”¨
        f"{len(state.transcripts)} æ¡å¯¹è¯",
        "å½•éŸ³å·²ç»“æŸ"
    )

def on_audio_stream(audio_data):
    """
    å®æ—¶éŸ³é¢‘æµå¤„ç†å›è°ƒ - ç´¯ç§¯éŸ³é¢‘åˆ°è¶³å¤Ÿé•¿åº¦åå†å¤„ç†
    audio_data: tuple (sample_rate, audio_array)
    """
    now = time.time()
    
    # ğŸ› è°ƒè¯•ï¼šæ£€æŸ¥éŸ³é¢‘æ•°æ®
    if audio_data is not None:
        print(f"[DEBUG] æ”¶åˆ°éŸ³é¢‘æ•°æ®: type={type(audio_data)}, is_recording={state.is_recording}, is_paused={state.is_paused}")
        if isinstance(audio_data, tuple) and len(audio_data) == 2:
            print(f"[DEBUG] sample_rate={audio_data[0]}, audio_shape={audio_data[1].shape if hasattr(audio_data[1], 'shape') else 'no shape'}")

    if not state.is_recording or state.is_paused:
        with state.buffer_lock:
            current_samples = state.total_audio_samples
        transcript_html = state.cached_transcript_html or format_transcript_html(
            state.transcripts, state.mapping_done, state.speaker_mapping
        )
        return (
            gr.update(value=transcript_html),
            f"{len(state.transcripts)} æ¡å¯¹è¯",
            f"ç´¯ç§¯éŸ³é¢‘: {current_samples / SAMPLE_RATE:.1f}ç§’"
        )
    
    if audio_data is None:
        print("[DEBUG] audio_data is None")
        with state.buffer_lock:
            current_samples = state.total_audio_samples
        transcript_html = state.cached_transcript_html or format_transcript_html(
            state.transcripts, state.mapping_done, state.speaker_mapping
        )
        return (
            gr.update(value=transcript_html),
            f"{len(state.transcripts)} æ¡å¯¹è¯",
            f"ç´¯ç§¯éŸ³é¢‘: {current_samples / SAMPLE_RATE:.1f}ç§’"
        )
    
    sample_rate, audio_array = audio_data
    
    # è½¬æ¢ä¸ºå•å£°é“(å¦‚æœæ˜¯ç«‹ä½“å£°)
    if len(audio_array.shape) > 1:
        audio_array = audio_array.mean(axis=1)
    
    # ğŸ”’ å§‹ç»ˆç´¯ç§¯éŸ³é¢‘åˆ°ç¼“å†²åŒºï¼ˆåŠ é”ä¿æŠ¤ï¼‰
    with state.buffer_lock:
        state.audio_buffer.append(audio_array)
        state.total_audio_samples += len(audio_array)
        current_duration = state.total_audio_samples / SAMPLE_RATE
        should_process = (state.total_audio_samples >= MIN_AUDIO_LENGTH 
                         and not state.is_processing)
    
    # ğŸ› è°ƒè¯•è¾“å‡º
    if current_duration > 0 and int(current_duration) % 5 == 0 and current_duration < int(current_duration) + 0.5:
        print(f"[DEBUG] ç´¯ç§¯éŸ³é¢‘: {current_duration:.1f}ç§’, éœ€è¦: {MIN_AUDIO_LENGTH/SAMPLE_RATE:.1f}ç§’, should_process={should_process}, is_processing={state.is_processing}")
    
    status_msg = f"ç´¯ç§¯éŸ³é¢‘: {current_duration:.1f}ç§’"
    
    # æ£€æŸ¥æ˜¯å¦ç´¯ç§¯åˆ°è¶³å¤Ÿé•¿åº¦ä¸”å½“å‰æ²¡æœ‰åœ¨å¤„ç†
    transcript_html = state.cached_transcript_html or format_transcript_html(
        state.transcripts, state.mapping_done, state.speaker_mapping
    )
    html_update = gr.update(value=transcript_html)

    if should_process:
        # æ ‡è®°ä¸ºå¤„ç†ä¸­
        state.is_processing = True
        
        # ğŸ”’ è·å–å½“å‰ç¼“å†²åŒºå¹¶æ¸…ç©ºï¼ˆåŠ é”ä¿æŠ¤ï¼‰
        with state.buffer_lock:
            combined_audio = np.concatenate(state.audio_buffer)
            state.audio_buffer = []  # æ¸…ç©ºç¼“å†²åŒºï¼Œæ–°éŸ³é¢‘ä¼šç»§ç»­ç´¯ç§¯åˆ°æ–°buffer
            state.total_audio_samples = 0
        
        # ğŸš€ åœ¨é”å¤–è¿›è¡Œè€—æ—¶æ“ä½œï¼ˆä¸é˜»å¡æ–°éŸ³é¢‘ç´¯ç§¯ï¼‰
        voice_ok, voiced_secs = has_enough_voice(combined_audio, sample_rate)

        if not voice_ok:
            status_msg = f"âš ï¸ è¯­éŸ³å¤ªçŸ­/å¤ªé™({voiced_secs:.1f}s),å·²è·³è¿‡"
            html_update = gr.update()  # ä¸æ›´æ–°HTML
        else:
            success = process_audio_chunk(combined_audio, sample_rate)
            
            if success:
                status_msg = f"âœ“ å·²å¤„ç†ç¬¬ {state.processed_chunks} æ®µéŸ³é¢‘ (è¯­éŸ³{voiced_secs:.1f}s)"
                # æœ‰æ–°å†…å®¹æ—¶åˆ·æ–°ç¼“å­˜å¹¶è®°å½•æ¸²æŸ“æ—¶é—´,å‡å°‘é—ªçƒ
                transcript_html = format_transcript_html(state.transcripts, state.mapping_done, state.speaker_mapping)
                state.cached_transcript_html = transcript_html
                state.last_rendered_version = state.transcript_version
                state.last_ui_render_time = now
                html_update = gr.update(value=transcript_html)
            else:
                status_msg = f"âš ï¸ å¤„ç†å¤±è´¥"
                html_update = gr.update()
        
        # å¤„ç†å®Œæˆï¼Œé‡Šæ”¾æ ‡è®°
        state.is_processing = False
    else:
        # æ²¡æœ‰æ–°å†…å®¹ä¸”è·ç¦»ä¸Šæ¬¡æ¸²æŸ“è¿‡çŸ­æ—¶,ç›´æ¥å¤ç”¨ç¼“å­˜ä»¥é™ä½åˆ·æ–°é¢‘ç‡
        need_render = (
            state.transcript_version != state.last_rendered_version
            or (now - state.last_ui_render_time) > 1.0
            or not state.cached_transcript_html
        )
        if need_render:
            transcript_html = format_transcript_html(state.transcripts, state.mapping_done, state.speaker_mapping)
            state.cached_transcript_html = transcript_html
            state.last_rendered_version = state.transcript_version
            state.last_ui_render_time = now
            html_update = gr.update(value=transcript_html)
        else:
            html_update = gr.update()  # ä¸å˜æ›´,é¿å…é—ªçƒ
    
    return (
        html_update,
        f"{len(state.transcripts)} æ¡å¯¹è¯",
        status_msg
    )

def apply_speaker_mapping(*args):
    """åº”ç”¨è¯´è¯äººèº«ä»½æ˜ å°„"""
    state.speaker_mapping = {}

    allowed_roles = set(ROLE_OPTIONS)

    n = MAX_SPEAKERS
    labels = list(args[:n])
    roles = list(args[n:2*n])
    names = list(args[2*n:3*n])

    for speaker_label, role_cn, name in zip(labels, roles, names):
        if not speaker_label:
            continue
        if role_cn not in allowed_roles:
            role_cn = "å…¶ä»–"

        # æ˜ å°„è§’è‰²
        role_map = {
            "åŒ»ç”Ÿ": "doctor",
            "æŠ¤å£«": "nurse",
            "æ‚£è€…": "patient",
            "å®¶å±": "family",
            "é™ªè¯Š": "family",
            "å®¶å±/é™ªè¯Š": "family",
            "å…¶ä»–": "other"
        }
        role = role_map.get(role_cn, "other")
        
        state.speaker_mapping[speaker_label] = {
            "role": role,
            "name": name or speaker_label
        }
    
    state.mapping_done = True
    
    # æ›´æ–°å¯¹è¯æ˜¾ç¤º
    updated_html = format_transcript_html(state.transcripts, True, state.speaker_mapping)
    state.cached_transcript_html = updated_html
    state.last_rendered_version = state.transcript_version
    state.last_ui_render_time = time.time()
    
    return (
        updated_html,
        gr.update(interactive=True),  # å¯ç”¨ç”ŸæˆæŠ¥å‘ŠæŒ‰é’®
        gr.update(value="<div style='color: #4cd964;'>âœ“ èº«ä»½è®¾ç½®å·²åº”ç”¨,å¯ä»¥ç”ŸæˆæŠ¥å‘Š</div>")
    )

def reset_speaker_mapping():
    """é‡ç½®è¯´è¯äººæ˜ å°„"""
    state.speaker_mapping = {}
    state.mapping_done = False
    
    # é‡æ–°ç”Ÿæˆé»˜è®¤æ˜ å°„
    mapping_data = create_speaker_mapping_ui(list(state.unique_speakers))
    
    return (
        mapping_data,
        format_transcript_html(state.transcripts, False, {}),
        gr.update(interactive=False),  # ç¦ç”¨ç”ŸæˆæŠ¥å‘Š
        gr.update(value="æç¤º:è¯·é‡æ–°è®¾ç½®è¯´è¯äººèº«ä»½"),
        *build_empty_mapping_updates()
    )

def generate_report():
    """ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š"""
    if not state.mapping_done:
        return "âŒ è¯·å…ˆå®Œæˆè¯´è¯äººèº«ä»½è®¾ç½®å¹¶ç‚¹å‡»\"åº”ç”¨è®¾ç½®\""
    
    # æ”¶é›†æ‚£è€…å’ŒåŒ»ç”Ÿçš„å¯¹è¯
    patient_texts = []
    doctor_texts = []
    all_dialogue = []
    
    for item in state.transcripts:
        speaker_label = item['speaker']
        text = item['text']
        time_str = f"{format_time(item['start'])}-{format_time(item['end'])}"
        
        if speaker_label in state.speaker_mapping:
            role = state.speaker_mapping[speaker_label]['role']
            name = state.speaker_mapping[speaker_label]['name']
            
            all_dialogue.append(f"**{name}** ({time_str}): {text}")
            
            if role in ['patient', 'family']:
                patient_texts.append(text)
            elif role in ['doctor', 'nurse']:
                doctor_texts.append(text)
    
    # ç”ŸæˆæŠ¥å‘Š
    report = f"""
# ğŸ“‹ é—®è¯Šç»“æ„åŒ–æŠ¥å‘Š

---

## ğŸ“Œ ç—…äººåŸºæœ¬ä¿¡æ¯
- **å°±è¯Šæ—¶é—´**: {state.start_time.strftime('%Y-%m-%d %H:%M:%S') if state.start_time else 'æœªçŸ¥'}
- **é—®è¯Šæ—¶é•¿**: {format_time(state.transcripts[-1]['end']) if state.transcripts else '00:00'}
- **å‚ä¸äººæ•°**: {len(state.unique_speakers)}äºº

---

## ğŸ—£ï¸ ç—…äººè‡ªè¿°
{' '.join(patient_texts) if patient_texts else 'æ— '}

---

## ğŸ©º åŒ»ç”Ÿé—®è¯Šæ‘˜è¦
{' '.join(doctor_texts) if doctor_texts else 'æ— '}

---

## ğŸ’¬ å®Œæ•´å¯¹è¯è®°å½•
{chr(10).join(all_dialogue)}

---

## ğŸ” åˆæ­¥è¯Šæ–­ä¸å»ºè®®
> *å¾…åŒ»ç”Ÿè¡¥å……...*

---

*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    return report

# ==================== Gradioç•Œé¢æ„å»º ====================

with gr.Blocks(
    title="æ™ºèƒ½åŒ»ç”Ÿé—®è¯ŠAIç³»ç»Ÿ",
) as demo:
    
    # æ ‡é¢˜
    gr.HTML("""
    <div class="header">
        <h1 style="margin: 0; display: flex; align-items: center; gap: 12px; font-size: 24px;">
            ğŸ©º æ™ºèƒ½åŒ»ç”Ÿé—®è¯ŠAIç³»ç»Ÿ
        </h1>
        <p style="margin: 8px 0 0 0; opacity: 0.9; font-size: 14px;">
            åŸºäºè¯­éŸ³è¯†åˆ«å’Œè¯´è¯äººåˆ†ç¦»çš„åŒ»ç–—é—®è¯Šè®°å½•ç³»ç»Ÿ
        </p>
    </div>
    """)
    
    with gr.Row():
        # å·¦ä¾§:é—®è¯Šå¯¹è¯
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“ é—®è¯Šå¯¹è¯")
            
            # æ§åˆ¶æŒ‰é’®
            with gr.Row():
                start_btn = gr.Button("â–¶ï¸ å¼€å§‹é—®è¯Š", variant="primary", size="lg")
                pause_btn = gr.Button("â¸ æš‚åœ", interactive=False)
                stop_btn = gr.Button("â¹ ç»“æŸé—®è¯Š", interactive=False, variant="stop")
            
            # çŠ¶æ€æŒ‡ç¤ºå™¨
            status_box = gr.HTML(
                "<div style='color: #666; text-align: center; padding: 10px;'>å°±ç»ª</div>",
                elem_classes="status-box"
            )
            
            # éŸ³é¢‘è¾“å…¥ - ç”¨äºå®æ—¶å½•éŸ³
            audio_input = gr.Audio(
                sources=["microphone"],
                type="numpy",
                streaming=True,
                label="å½•éŸ³",
                show_label=False,
                visible=False  # éšè—,è‡ªåŠ¨è§¦å‘
            )
            
            # å¯¹è¯è½¬å½•çª—å£
            with gr.Row():
                gr.Markdown("**å®æ—¶å¯¹è¯è½¬å½•**")
                transcript_counter = gr.Markdown("0 æ¡å¯¹è¯")
            
            # éŸ³é¢‘çŠ¶æ€æç¤º
            audio_status = gr.Markdown("ç­‰å¾…å¼€å§‹å½•éŸ³...", elem_classes="status-box")
            
            transcript_display = gr.HTML(
                value="<div style='color: #999; text-align: center; padding: 20px;'>ç‚¹å‡»\"å¼€å§‹é—®è¯Š\"åå¼€å§‹å½•éŸ³</div>"
            )
            
            # è¯´è¯äººèº«ä»½è®¾ç½®
            gr.Markdown("### ğŸ‘¤ è¯´è¯äººèº«ä»½è®¾ç½®")
            mapping_hint = gr.Markdown(
                "æç¤º:é—®è¯Šç»“æŸå,è¯·ä¸ºæ£€æµ‹åˆ°çš„è¯´è¯äººåˆ†é…èº«ä»½ã€‚è®¾ç½®ä¸º\"åŒ»ç”Ÿ\"æˆ–\"æŠ¤å£«\"èº«ä»½çš„æ¶ˆæ¯å°†æ˜¾ç¤ºåœ¨å³ä¾§,å…¶ä»–èº«ä»½æ¶ˆæ¯æ˜¾ç¤ºåœ¨å·¦ä¾§ã€‚"
            )

            # è‡ªå®šä¹‰ä¸‹æ‹‰æ§ä»¶è¡Œ
            label_boxes = []
            role_dropdowns = []
            name_boxes = []
            for i in range(MAX_SPEAKERS):
                with gr.Row():
                    lbl = gr.Textbox(label=f"è¯´è¯äºº{i+1}", interactive=False, visible=False)
                    role = gr.Dropdown(choices=ROLE_OPTIONS, value="æ‚£è€…", label="è§’è‰²", visible=False)
                    name = gr.Textbox(label="å§“å", visible=False)
                label_boxes.append(lbl)
                role_dropdowns.append(role)
                name_boxes.append(name)
    
            with gr.Row():
                reset_mapping_btn = gr.Button("ğŸ”„ é‡ç½®è®¾ç½®", variant="secondary", interactive=False)
                apply_mapping_btn = gr.Button("âœ“ åº”ç”¨è®¾ç½®", variant="primary", interactive=False)
            
            generate_report_btn = gr.Button(
                "ğŸ“‹ ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š",
                variant="primary",
                interactive=False,
                size="lg"
            )
        
        # å³ä¾§:ç»“æ„åŒ–æŠ¥å‘Š
        with gr.Column(scale=1):
            gr.Markdown("### ğŸ“„ ç»“æ„åŒ–æŠ¥å‘Š")
            report_display = gr.Markdown(
                value="""
---
è¯·å…ˆå®Œæˆä»¥ä¸‹æ­¥éª¤:
1. ç‚¹å‡»"å¼€å§‹é—®è¯Š"è¿›è¡Œå½•éŸ³
2. ç»“æŸé—®è¯Šåè®¾ç½®è¯´è¯äººèº«ä»½
3. ç‚¹å‡»"åº”ç”¨è®¾ç½®"
4. ç‚¹å‡»"ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š"
---
                """
            )
    
    # ä½¿ç”¨è¯´æ˜
    with gr.Accordion("ğŸ“– ä½¿ç”¨è¯´æ˜", open=False):
        gr.Markdown("""
### æ“ä½œæµç¨‹
1. **å¼€å§‹é—®è¯Š**: ç‚¹å‡»"å¼€å§‹é—®è¯Š"æŒ‰é’®,ç³»ç»Ÿè‡ªåŠ¨å¼€å§‹å½•éŸ³
2. **å®æ—¶è½¬å½•**: ç³»ç»Ÿæ¯10ç§’è‡ªåŠ¨å¤„ç†ä¸€æ¬¡éŸ³é¢‘å¹¶æ˜¾ç¤ºè½¬å½•ç»“æœ
3. **æš‚åœ/ç»§ç»­**: å¯éšæ—¶æš‚åœæˆ–ç»§ç»­å½•éŸ³
4. **ç»“æŸé—®è¯Š**: ç‚¹å‡»"ç»“æŸé—®è¯Š",ç³»ç»Ÿä¼šè‡ªåŠ¨åˆå¹¶ç›¸é‚»åŒä¸€è¯´è¯äººçš„å¯¹è¯
5. **èº«ä»½æ˜ å°„**: ä¸ºæ¯ä¸ªæ£€æµ‹åˆ°çš„è¯´è¯äººè®¾ç½®è§’è‰²å’Œå§“å
6. **åº”ç”¨è®¾ç½®**: ç‚¹å‡»åå¯¹è¯çª—å£ä¼šæŒ‰èº«ä»½é‡æ–°æ’åˆ—(åŒ»é™¢æ–¹å³ä¾§,æ‚£è€…æ–¹å·¦ä¾§)
7. **ç”ŸæˆæŠ¥å‘Š**: ç”ŸæˆåŒ…å«å®Œæ•´ä¿¡æ¯çš„ç»“æ„åŒ–åŒ»ç–—æŠ¥å‘Š

### è¯´è¯äººè§’è‰²è¯´æ˜
- **åŒ»ç”Ÿ/æŠ¤å£«**: åŒ»é™¢æ–¹äººå‘˜,å¯¹è¯æ˜¾ç¤ºåœ¨å³ä¾§(è“è‰²)
- **æ‚£è€…/å®¶å±/é™ªè¯Š**: æ‚£è€…æ–¹äººå‘˜,å¯¹è¯æ˜¾ç¤ºåœ¨å·¦ä¾§(ç»¿è‰²)
- **å…¶ä»–**: å…¶ä»–å‚ä¸è€…

### æŠ€æœ¯ç‰¹ç‚¹
- âœ… å®æ—¶è¯­éŸ³è¯†åˆ«
- âœ… è‡ªåŠ¨è¯´è¯äººåˆ†ç¦»
- âœ… æ™ºèƒ½å¯¹è¯åˆå¹¶
- âœ… ç»“æ„åŒ–æŠ¥å‘Šç”Ÿæˆ
        """)
    
    # ==================== äº‹ä»¶ç»‘å®š ====================
    
    # å¼€å§‹é—®è¯Š - è§¦å‘å½•éŸ³å¼€å§‹
    def on_start():
        updates = start_consultation()
        base = list(updates)
        # æ‰“å¼€éŸ³é¢‘è¾“å…¥ç»„ä»¶
        base[12] = gr.update(visible=True)
        base += list(build_empty_mapping_updates())
        return tuple(base)
    
    mapping_state = gr.State()

    start_click = start_btn.click(
        fn=on_start,
        outputs=[
            start_btn, pause_btn, stop_btn, status_box,
            transcript_display,
            mapping_hint, apply_mapping_btn, reset_mapping_btn,
            generate_report_btn, report_display, transcript_counter,
            audio_status, audio_input,
            mapping_state
        ]
        + label_boxes
        + role_dropdowns
        + name_boxes
    )
    
    # éŸ³é¢‘æµå¤„ç† - å®æ—¶è½¬å½•(ç´¯ç§¯åˆ°è¶³å¤Ÿé•¿åº¦)
    audio_input.stream(
        fn=on_audio_stream,
        inputs=[audio_input],
        outputs=[transcript_display, transcript_counter, audio_status]
    )
    
    # æš‚åœ/ç»§ç»­
    pause_btn.click(
        fn=pause_consultation,
        outputs=[status_box, pause_btn]
    )
    
    # ç»“æŸé—®è¯Š
    stop_btn.click(
        fn=stop_consultation,
        outputs=[
            start_btn, pause_btn, stop_btn, status_box,
            transcript_display, mapping_state,
            mapping_hint, apply_mapping_btn, reset_mapping_btn,
            generate_report_btn, transcript_counter, audio_status
        ]
    ).then(
        fn=build_mapping_updates,
        inputs=[mapping_state],
        outputs=label_boxes + role_dropdowns + name_boxes
    ).then(
        fn=lambda: gr.update(visible=False),
        outputs=[audio_input]
    )
    
    # åº”ç”¨èº«ä»½æ˜ å°„
    apply_mapping_btn.click(
        fn=apply_speaker_mapping,
        inputs=label_boxes + role_dropdowns + name_boxes,
        outputs=[transcript_display, generate_report_btn, status_box]
    )
    
    # é‡ç½®æ˜ å°„
    reset_mapping_btn.click(
        fn=reset_speaker_mapping,
        outputs=[
            mapping_state,
            transcript_display,
            generate_report_btn,
            mapping_hint,
        ] + label_boxes + role_dropdowns + name_boxes
    )
    
    # ç”ŸæˆæŠ¥å‘Š
    generate_report_btn.click(
        fn=generate_report,
        outputs=[report_display]
    )

if __name__ == "__main__":
    demo.launch(
        share=False,
        server_name="0.0.0.0",
        server_port=7860,
        show_error=True,
        theme=gr.themes.Soft(),
        css="""
        .header {
            background: linear-gradient(to right, #1e90ff, #1a7feb);
            color: white;
            padding: 20px 25px;
            border-radius: 10px;
            margin-bottom: 20px;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        .status-box {
            padding: 12px;
            border-radius: 8px;
            background: #f5f5f5;
            text-align: center;
            font-weight: 500;
        }
        """
    )